# PredicciÃ³n de Stock con Redes Neuronales Recurrentes (GRU)

[![Python](https://img.shields.io/badge/Python-3.8%2B-blue.svg)](https://www.python.org/)
[![TensorFlow](https://img.shields.io/badge/TensorFlow-2.x-orange.svg)](https://www.tensorflow.org/)
[![Marimo](https://img.shields.io/badge/Marimo-Notebooks-purple.svg)](https://marimo.io/)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)

> Sistema inteligente de predicciÃ³n de niveles de inventario utilizando aprendizaje profundo y series temporales.

---

## Autores

**Felipe Peralta** y **Samantha Suquilanda**  
*Universidad - 7mo Semestre*  
*Curso: Aprendizaje AutomÃ¡tico*

---

## DescripciÃ³n del Proyecto

Este proyecto implementa un modelo de **aprendizaje profundo basado en GRU (Gated Recurrent Units)** para predecir los niveles de stock en sistemas de gestiÃ³n de inventarios. El modelo aprende de patrones temporales histÃ³ricos para anticipar la cantidad disponible de productos, permitiendo optimizar las decisiones de reabastecimiento y reducir costos operacionales.

### Objetivos

- Predecir `quantity_available` (stock disponible) con 7 dÃ­as de anticipaciÃ³n
- Lograr un error promedio (MAE) menor al 5% del rango de stock
- Desarrollar un pipeline completo de ML: datos â†’ modelo â†’ producciÃ³n
- Implementar un sistema robusto de inferencia con validaciÃ³n de entradas

---

## CaracterÃ­sticas Principales

- **Modelo GRU optimizado** con 18,497 parÃ¡metros entrenables
- **PrecisiÃ³n del 97%** (error relativo de solo 3%)
- **Pipeline automatizado** de preprocesamiento y feature engineering
- **FunciÃ³n de predicciÃ³n lista para producciÃ³n** con validaciÃ³n exhaustiva
- **Notebooks interactivos Marimo** para exploraciÃ³n y anÃ¡lisis
- **Dataset sintÃ©tico realista** con 79,173 registros temporales

---

## Resultados Destacados

| MÃ©trica | Valor | InterpretaciÃ³n |
|---------|-------|----------------|
| **MAE** | 193.03 unidades | Error promedio por predicciÃ³n |
| **RMSE** | 271.37 unidades | Error cuadrÃ¡tico medio |
| **Error Relativo** | 3.00% | Porcentaje de error sobre rango total (6,435 u) |
| **Ã‰pocas de entrenamiento** | 53 de 100 | Convergencia eficiente con early stopping |
| **PrecisiÃ³n general** | 97% | Alto nivel de exactitud |

### Curva de Aprendizaje

```bash
Convergencia del modelo:
Ã‰poca 1:  Loss: 0.0250 â†’ Val Loss: 0.0180
Ã‰poca 10: Loss: 0.0055 â†’ Val Loss: 0.0048
Ã‰poca 53: Loss: 0.0035 â†’ Val Loss: 0.0042 âœ“ (Mejor modelo)
```

---

## Estructura del Proyecto

```bash
practica-1/
â”œâ”€â”€ ğŸ“ notebooks/           # Notebooks Marimo interactivos
â”‚   â”œâ”€â”€ fase01.py          # Fase 1: AnÃ¡lisis y PreparaciÃ³n de Datos
â”‚   â”œâ”€â”€ fase02.py          # Fase 2: Entrenamiento del Modelo
â”‚   â””â”€â”€ fase03.py          # Fase 3: Inferencia y Despliegue
â”‚
â”œâ”€â”€ ğŸ“ data/
â”‚   â”œâ”€â”€ raw/               # Datos originales
â”‚   â”‚   â””â”€â”€ dataset_inventario_secuencial_completo.csv
â”‚   â””â”€â”€ processed/         # Datos procesados
â”‚       â”œâ”€â”€ df_processed_features.csv
â”‚       â”œâ”€â”€ X_train.npy
â”‚       â”œâ”€â”€ X_val.npy
â”‚       â”œâ”€â”€ y_train.npy
â”‚       â””â”€â”€ y_val.npy
â”‚
â”œâ”€â”€ ğŸ“ models/             # Modelos entrenados
â”‚   â””â”€â”€ best_model.keras   # Mejor modelo GRU (Ã©poca 53)
â”‚
â”œâ”€â”€ ğŸ“ scalers/            # Objetos de preprocesamiento
â”‚   â”œâ”€â”€ min_max_scaler.joblib
â”‚   â”œâ”€â”€ le_product_id.joblib
â”‚   â””â”€â”€ le_supplier_id.joblib
â”‚
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md              # Este archivo
```

---

## TecnologÃ­as Utilizadas

### Core ML/DL

- **TensorFlow/Keras** 2.x - Framework de deep learning
- **NumPy** - ComputaciÃ³n numÃ©rica
- **Pandas** - ManipulaciÃ³n de datos

### Preprocesamiento

- **Scikit-learn** - CodificaciÃ³n y normalizaciÃ³n
- **Joblib** - SerializaciÃ³n de objetos

### Notebooks Interactivos

- **Marimo** - Notebooks reactivos en Python

### VisualizaciÃ³n

- **Matplotlib** - GrÃ¡ficos estÃ¡ticos
- **Seaborn** - Visualizaciones estadÃ­sticas
- **Plotly** - GrÃ¡ficos interactivos

---

## InstalaciÃ³n

### Prerrequisitos

```bash
Python 3.8 o superior
pip (gestor de paquetes de Python)
```

### InstalaciÃ³n de Dependencias

```bash
# Clonar el repositorio
git clone https://github.com/FepDev25/Practica-1-Aprendizaje-Automatico.git
cd Practica-1-Aprendizaje-Automatico

# Crear entorno virtual (recomendado)
python -m venv venv
source venv/bin/activate  # En Windows: venv\Scripts\activate

# Instalar dependencias
pip install tensorflow numpy pandas scikit-learn joblib matplotlib seaborn plotly marimo
```

---

## Uso del Proyecto

### ExploraciÃ³n de Datos (Fase 1)

```bash
marimo edit notebooks/fase01.py
```

**Contenido:**

- Carga y anÃ¡lisis exploratorio del dataset
- Limpieza y transformaciÃ³n de datos
- Feature engineering temporal
- CodificaciÃ³n y normalizaciÃ³n
- CreaciÃ³n de secuencias temporales

### Entrenamiento del Modelo (Fase 2)

```bash
marimo edit notebooks/fase02.py
```

**Contenido:**

- ConstrucciÃ³n de la arquitectura GRU
- Entrenamiento con callbacks (Early Stopping, ModelCheckpoint)
- EvaluaciÃ³n de mÃ©tricas (MAE, RMSE)
- AnÃ¡lisis de curvas de aprendizaje
- AnÃ¡lisis de distribuciÃ³n de errores

### Inferencia y Despliegue (Fase 3)

```bash
marimo edit notebooks/fase03.py
```

**Contenido:**

- Carga de artefactos de producciÃ³n
- FunciÃ³n `predict_demand()` para predicciones
- ValidaciÃ³n con productos reales
- Propuesta de API REST con FastAPI

---

## Ejemplo de PredicciÃ³n

```python
from notebooks.fase03 import predict_demand

# Predecir stock para un producto especÃ­fico
stock_predicho = predict_demand(
    product_id_str="PROD-00136830",
    target_date_str="2025-10-31"
)

print(f"Stock predicho: {stock_predicho:.2f} unidades")
# Salida: Stock predicho: 4253.67 unidades
```

### Casos de Uso

**Reabastecimiento automÃ¡tico**: Generar Ã³rdenes cuando predicciÃ³n < punto de reorden  
**OptimizaciÃ³n de almacÃ©n**: Redistribuir inventario segÃºn demanda prevista  
**Alertas tempranas**: Notificar sobre posibles desabastecimientos  
**PlanificaciÃ³n financiera**: Estimar capital inmovilizado en inventario

---

## Arquitectura del Modelo

```python
Model: "Modelo_GRU_Prediccion_Stock"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Capa_Entrada_GRU (GRU)       (None, 64)                18,240    
_________________________________________________________________
Capa_Dropout (Dropout)       (None, 64)                0         
_________________________________________________________________
Capa_Salida_Prediccion       (None, 1)                 65        
=================================================================
Total params: 18,305
Trainable params: 18,305
Non-trainable params: 0
```

### ConfiguraciÃ³n de Entrenamiento

- **Optimizador**: Adam (learning_rate=0.001)
- **FunciÃ³n de pÃ©rdida**: Mean Squared Error (MSE)
- **MÃ©trica**: Mean Absolute Error (MAE)
- **Batch size**: 64
- **Ventana temporal**: 7 dÃ­as (N_STEPS)
- **Features de entrada**: 30 variables

---

## Dataset

### CaracterÃ­sticas del Dataset SintÃ©tico

- **79,173 registros** con evoluciÃ³n temporal
- **28 variables** originales
- **~7,900 productos Ãºnicos**
- **PerÃ­odo temporal**: Datos secuenciales realistas

### Variables Principales

| CategorÃ­a | Variables |
|-----------|-----------|
| **Stock** | `quantity_available`, `quantity_on_hand`, `quantity_reserved` |
| **GestiÃ³n** | `minimum_stock_level`, `reorder_point`, `optimal_stock_level` |
| **Temporales** | `created_at`, `last_updated_at`, `last_stock_count_date` |
| **CategÃ³ricas** | `warehouse_location`, `stock_status`, `product_id` |
| **Derivadas** | `average_daily_usage`, `unit_cost`, `total_value` |

### Feature Engineering

```python
# Variables temporales creadas
- dia_del_mes, dia_de_la_semana, mes, trimestre
- es_fin_de_semana (variable binaria)

# Variables derivadas del negocio
- dias_para_vencimiento
- antiguedad_producto_dias  
- ratio_uso_stock
```

---

## MetodologÃ­a

### Pipeline de ML Completo

```bash
1. DATOS CRUDOS
   â†“
2. LIMPIEZA Y TRANSFORMACIÃ“N
   â†“
3. FEATURE ENGINEERING
   â†“
4. CODIFICACIÃ“N (Label Encoding + One-Hot)
   â†“
5. NORMALIZACIÃ“N (MinMaxScaler [0,1])
   â†“
6. CREACIÃ“N DE SECUENCIAS (Ventana deslizante 7 dÃ­as)
   â†“
7. DIVISIÃ“N TEMPORAL (80% train / 20% validation)
   â†“
8. ENTRENAMIENTO GRU (Early Stopping)
   â†“
9. EVALUACIÃ“N Y ANÃLISIS
   â†“
10. FUNCIÃ“N DE INFERENCIA
```

### DivisiÃ³n de Datos

- **Train set**: 59,394 secuencias (80%)
- **Validation set**: 14,820 secuencias (20%)
- **DivisiÃ³n temporal** (no aleatoria para respetar cronologÃ­a)

---

## AnÃ¡lisis de Rendimiento

### Rendimiento por Rango de Stock

| Rango de Stock | Muestras | MAE (unidades) | Error % |
|----------------|----------|----------------|---------|
| **Bajo** (0-33%) | 4,940 | 150 | 4.2% |
| **Medio** (33-66%) | 4,940 | 185 | 3.5% |
| **Alto** (66-100%) | 4,940 | 245 | 2.8% |

### DistribuciÃ³n de Errores

```bash
EstadÃ­sticas del Error Absoluto:
- Media: 193.03 unidades
- Mediana: 161.8 unidades
- Q1 (25%): 73.6 unidades
- Q3 (75%): 293.5 unidades
```

**InterpretaciÃ³n**: El 50% de las predicciones tienen un error inferior a 162 unidades, lo que representa una alta precisiÃ³n considerando el rango total del inventario (0-6,435 unidades).

---

## Contribuciones

Este proyecto fue desarrollado con fines acadÃ©micos como parte del curso de Aprendizaje AutomÃ¡tico.

Si encuentras errores o tienes sugerencias de mejora:

1. Abre un **Issue** describiendo el problema
2. EnvÃ­a un **Pull Request** con tu propuesta

---

## Contacto

**Felipe Peralta** - [GitHub](https://github.com/FepDev25)  
**Samantha Suquilanda**
